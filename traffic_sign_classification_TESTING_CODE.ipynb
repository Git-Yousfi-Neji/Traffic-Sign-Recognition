{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_sign_classification_TESTING_CODE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMr4bhAL17+AosYOfHdLWK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Git-Yousfi-Neji/Traffic-Sign-Recognition/blob/main/traffic_sign_classification_TESTING_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b78oRzJq6LHJ"
      },
      "source": [
        "# **Connecting to drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6NKfYkN6J2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495a12e3-6940-440a-f38f-ccfc745e029d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\",force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYsEhZ1Z3viy"
      },
      "source": [
        "# **Importing libraries**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yqF20Sy3Nye"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "from random import choice\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTmeL69f4TqU"
      },
      "source": [
        "# **Importing the model**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y31rlbL83nuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfefaf60-0102-4662-88e6-80122e2942c3"
      },
      "source": [
        "model_path = 'drive/My Drive/Colab Notebooks/traffic signs python/traffic_sign/traffic_sign_model.h5'\n",
        "model = load_model(model_path)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 60)        1560      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 60)        90060     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 60)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 30)        16230     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 30)          8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 30)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 4, 30)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               240500    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 43)                21543     \n",
            "=================================================================\n",
            "Total params: 378,023\n",
            "Trainable params: 378,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiyMJEO73nm_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2f301883-53c0-4936-f508-f5da9b3cdd8b"
      },
      "source": [
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "def equalize(img):\n",
        "    img =cv2.equalizeHist(img)\n",
        "    return img\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "\n",
        "data = pd.read_csv('drive/My Drive/Colab Notebooks/traffic signs python/traffic_sign/labels.csv')\n",
        "images_path = 'drive/My Drive/Colab Notebooks/traffic signs python/test.jpg'\n",
        "#print(data.head(5))\n",
        "###############\n",
        "#img_test = cv2.imread('drive/My Drive/Colab Notebooks/traffic signs python/traffic_sign/myData/0/0_10000_1577671998.6491628.png')\n",
        "img_test = cv2.imread(images_path)\n",
        "img = cv2.resize(img_test,(32,32))\n",
        "print('img shape0',img.shape)\n",
        "img = np.array(img)\n",
        "img = preprocessing(img)\n",
        "img = img.reshape(1, 32, 32, 1)\n",
        "print('img shape',img.shape)\n",
        "#img = img.reshape(1, 32, 32, 1)\n",
        "#img = cv2.resize(img_test,(32,32))\n",
        "print(img.shape)\n",
        "\n",
        "print('predecting..')\n",
        "pr=  model.predict(img)\n",
        "lis = list(pr[0])\n",
        "print(lis)\n",
        "print([round(i) for i in lis])\n",
        "###############\n",
        "\"\"\"\n",
        "classId = list(data['ClassId'])\n",
        "labels = list(data['Name'])\n",
        "classId_classNo = dict(list(zip(classId,labels)))\n",
        "#list_images = os.listdir(images_path)\n",
        "images = list()\n",
        "for index in range(len(list_images)):\n",
        "    images.append(cv2.imread(images_path + '/' + list_images[index]))\n",
        "\n",
        "images = list(map(np.asarray,images))\n",
        "images = [cv2.resize(image,(32,32)) for image in images]\n",
        "images = list(map(preprocessing,images))\n",
        "plt.imshow(images[5])\n",
        "plt.show()\n",
        "images = [image.reshape(1,32,32,1) for image in images]\n",
        "\n",
        "\n",
        "\n",
        "pr=  model.predict(img)\n",
        "lis = list(pr[0])\n",
        "print([round(i) for i in lis])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img shape0 (32, 32, 3)\n",
            "img shape (1, 32, 32, 1)\n",
            "(1, 32, 32, 1)\n",
            "predecting..\n",
            "[7.5046955e-08, 0.00022620881, 1.7670078e-06, 6.9421094e-07, 2.981645e-08, 2.6126007e-05, 7.93134e-06, 2.3607042e-07, 1.2246487e-10, 3.2186433e-06, 6.305432e-05, 0.00047560892, 1.2076706e-06, 2.724519e-08, 1.1452567e-12, 7.664157e-10, 2.6621672e-08, 8.20912e-10, 4.4806457e-05, 1.0106042e-07, 5.3952102e-05, 6.5103322e-06, 1.07728354e-07, 3.3278966e-06, 2.4054245e-07, 1.4898348e-05, 1.0071623e-06, 3.7282157e-06, 0.7656244, 4.5303415e-05, 0.0016555182, 1.9109288e-07, 2.7525446e-10, 5.681511e-06, 0.0003538901, 0.22396064, 1.835029e-05, 5.7807567e-05, 3.220736e-05, 1.0578377e-10, 0.0073101893, 1.811586e-09, 9.4837986e-07]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nclassId = list(data['ClassId'])\\nlabels = list(data['Name'])\\nclassId_classNo = dict(list(zip(classId,labels)))\\n#list_images = os.listdir(images_path)\\nimages = list()\\nfor index in range(len(list_images)):\\n    images.append(cv2.imread(images_path + '/' + list_images[index]))\\n\\nimages = list(map(np.asarray,images))\\nimages = [cv2.resize(image,(32,32)) for image in images]\\nimages = list(map(preprocessing,images))\\nplt.imshow(images[5])\\nplt.show()\\nimages = [image.reshape(1,32,32,1) for image in images]\\n\\n\\n\\npr=  model.predict(img)\\nlis = list(pr[0])\\nprint([round(i) for i in lis])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pffPd0NY5C8g"
      },
      "source": [
        "# **Animation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Gpp3TNHhSr"
      },
      "source": [
        "def animate(i, data1, data2, line1, line2):\n",
        "    temp1 = data1.iloc[:int(i+1)]\n",
        "    temp2 = data2.iloc[:int(i+1)]\n",
        "\n",
        "    line1.set_data(temp1.index, temp1.value)\n",
        "    line2.set_data(temp2.index, temp2.value)\n",
        "\n",
        "    return (line1, line2)\n",
        "\n",
        "\n",
        "def create_loss_animation(model_type, data1, data2):\n",
        "    fig = plt.figure()\n",
        "    plt.title(f'Loss on Train & Test', fontsize=25)\n",
        "    plt.xlabel('Epoch', fontsize=20)\n",
        "    plt.ylabel('Loss MSE for Sx-Sy & Sxy', fontsize=20)\n",
        "    plt.xlim(min(data1.index.min(), data2.index.min()), max(data1.index.max(), data2.index.max()))\n",
        "    plt.ylim(min(data1.value.min(), data2.value.min()), max(data1.value.max(), data2.value.max()))\n",
        "\n",
        "    l1, = plt.plot([], [], 'o-', label='Train Loss', color='b', markevery=[-1])\n",
        "    l2, = plt.plot([], [], 'o-', label='Test Loss', color='r', markevery=[-1])\n",
        "    plt.legend(loc='center right', fontsize='xx-large')\n",
        "\n",
        "    Writer = animation.writers['ffmpeg']\n",
        "    writer = Writer(fps=5, bitrate=1800)\n",
        "\n",
        "    ani = matplotlib.animation.FuncAnimation(fig, animate, fargs=(data1, data2, l1, l2), repeat=True, interval=1000, repeat_delay=1000)\n",
        "    ani.save(f'{model_type}.mp4', writer=writer)\n",
        "\n",
        "# create datasets\n",
        "x = np.linspace(0,150,50)\n",
        "y1 = 41*np.exp(-x/20)\n",
        "y2 = 35*np.exp(-x/50)\n",
        "\n",
        "my_data_number_1 = pd.DataFrame({'x':x, 'value':y1}).set_index('x')\n",
        "my_data_number_2 = pd.DataFrame({'x':x, 'value':y2}).set_index('x')\n",
        "\n",
        "create_loss_animation('test', my_data_number_1, my_data_number_2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}